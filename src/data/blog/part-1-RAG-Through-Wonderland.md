---
title: "RAG Through Wonderland â€” Part 1: Setting Up AliceEval"
author: Gautam G Sabhahit
pubDatetime: "2025-11-10T00:00:00Z"
slug: part-1-rag-through-wonderland
featured: false
draft: false
tags:
  - RAG
  - evaluation
  - alice-eval
ogImage: ../../assets/images/posts/rag-through-wonderland/part-1/cover.png
description: "Kick off the RAG Through Wonderland series by defining AliceEval and outlining the five-level journey from factual recall to external knowledge synthesis."
canonicalURL: https://lazybuilds.com/rag-through-wonderland-part-1
---

# ðŸ•³ï¸ AliceEval: Setting Up Wonderland  
*Part 1 of the â€œRAG Through Wonderlandâ€ Series*

> â€œWho in the world am I? Ah, thatâ€™s the great puzzle.â€  
> â€” *Alice, Chapter 2*

---

## ðŸŒ± Entering the Rabbit Hole

Every adventure starts with curiosity â€” and for me, that curiosity began with a single question:  
**Can I truly understand how RAG systems think, not just how they work?**

Like Alice chasing the White Rabbit, I wanted to follow my curiosity down a structured path â€” not into chaos, but into **clarity**.  
Thatâ€™s how **AliceEval** was born: a personal learning framework designed to take me from *â€œretrieving paragraphsâ€* to *â€œretrieving meaning.â€*

This is the first chapter in a six-part journey where Iâ€™ll progressively build and evaluate a Retrieval-Augmented Generation (RAG) system â€” one that can reason about the world of *Aliceâ€™s Adventures in Wonderland* as intelligently as it recalls it.

---

## ðŸŽ¯ The Goal of the Journey

Iâ€™m not trying to benchmark a product or publish a paper â€” Iâ€™m trying to **learn by building**.

Over the coming weeks, Iâ€™ll evolve my RAG system through **five distinct levels of complexity**, each with its own dataset of questions, evaluation criteria, and lessons.

At each level, Iâ€™ll:
1. Implement or improve a RAG setup.
2. Evaluate its ability to answer increasingly complex questions.
3. Reflect on *why* it succeeds or fails.
4. Iterate until it reaches a **10/10 score** for that level.

By the end, I should understand not just *how to retrieve knowledge*, but *how retrieval becomes reasoning.*

---

## ðŸ§© Why Alice in Wonderland?

Carrollâ€™s *Aliceâ€™s Adventures in Wonderland* is the perfect playground for this experiment.  
Itâ€™s rich, surreal, layered â€” a story where logic itself becomes fluid.

Hereâ€™s why it fits so beautifully for RAG evaluation:
- Itâ€™s **public domain**, short, and semantically dense.
- It contains **clear facts** (â€œWho stole the tarts?â€), **localized reasoning** (â€œWhy did Alice cry?â€), and **abstract themes** (â€œWhat does growing up mean?â€).
- It oscillates between sense and nonsense â€” which makes it ideal to test how a model handles *ambiguity, contradiction, and metaphor.*

Just as Aliceâ€™s perception evolves through the story, Iâ€™ll evolve my RAG through structured experimentation â€” from *recall* â†’ *reasoning* â†’ *reflection*.

---

## ðŸ§± The Five Levels of Wonderland

Each level of AliceEval represents a distinct form of reasoning that a RAG system must master.  
Think of them as **five progressively deeper layers** of understanding â€” from what happened, to why it happened, to what it means.

| Level | Focus | Description | What It Tests |
|-------|--------|--------------|----------------|
| **Level 1 â€” Factual Recall** | Literal comprehension | Answering direct questions that exist word-for-word in the book. | Tests retrieval accuracy, chunk quality, and embedding relevance. |
| **Level 2 â€” Contextual Reasoning** | Local logic | Understanding short cause-effect relationships within or across nearby passages. | Tests multi-chunk retrieval, contextual linking, and coherence. |
| **Level 3 â€” Thematic Synthesis** | Symbolic and narrative connection | Summarizing or interpreting the storyâ€™s broader themes. | Tests summarization quality, semantic merging, and information hierarchy. |
| **Level 4 â€” Relational Reasoning** | Multi-hop understanding | Analyzing relationships and abstract logic between characters or events. | Tests entity linking, graph traversal, and multi-step reasoning. |
| **Level 5 â€” External Knowledge Integration** | Cross-domain synthesis | Bringing in real-world context (Carrollâ€™s life, Victorian culture, literary criticism). | Tests external corpus retrieval, source routing, and interpretive reasoning. |

Each level is not just harder â€” itâ€™s *qualitatively different.*  
To progress, the system must adapt: improving retrieval methods, context synthesis, and conceptual grounding.

---

## ðŸ§  What Each Level Teaches

### ðŸªž Level 1: The Mirror of Memory  
This stage tests whether a RAG can do the simplest task â€” find and reproduce *exact facts* from a text.  
Success here isnâ€™t about intelligence; itâ€™s about alignment.  
If I canâ€™t retrieve â€œWho is the White Rabbit?â€, thereâ€™s no point in chasing Wonderlandâ€™s deeper mysteries.

---

### ðŸŒ€ Level 2: The Pool of Context  
Once facts work, context begins.  
Here Iâ€™ll test questions like â€œWhy does Alice cry after shrinking?â€ â€” requiring multiple passages and a sense of *story flow*.  
This is where retrieval becomes narrative comprehension.  
I expect to experiment with chunk sizes, reranking, and query expansion here.

---

### ðŸŒ¸ Level 3: The Garden of Meaning  
At this stage, literal retrieval isnâ€™t enough.  
The questions become interpretive â€” â€œHow do Aliceâ€™s size changes reflect emotional growth?â€  
This requires summarization, paraphrase understanding, and a touch of symbolic reasoning.  
Iâ€™ll start testing hierarchical retrieval and map-reduce summarization chains.

---

### â™Ÿï¸ Level 4: The Queenâ€™s Logic  
Now we step into *graph-level reasoning*.  
Questions like â€œHow do authority figures in Wonderland shape Aliceâ€™s autonomy?â€ require understanding relationships, not paragraphs.  
This will push me toward entity extraction, multi-hop reasoning, and possibly graph databases.

---

### ðŸ” Level 5: Through the Looking Glass  
The final level goes beyond the text â€” connecting *Alice* to *Carroll* and his world.  
Questions like â€œHow does Victorian society influence Carrollâ€™s satire?â€ demand integration with external sources and interpretive reasoning.  
This is where RAG becomes knowledge orchestration â€” a bridge between text and context.

---

## âš™ï¸ Why Build This Way?

RAG systems are often presented as monoliths: **embed â†’ retrieve â†’ generate**.  
But in practice, they evolve through iterations of *complexity and failure*.

By splitting this journey into five levels, I can isolate:
- **Where** retrieval breaks down.
- **When** reasoning starts to appear.
- **How** adding structure (reranking, summarization, graph traversal) changes performance.

This isnâ€™t about pushing state-of-the-art â€” itâ€™s about *developing intuition.*  
Each failure will be a clue. Each improvement, a reflection of deeper understanding.

---

## ðŸ“˜ What Comes Next

In **Part 2: Finding the Rabbit Hole**, Iâ€™ll start small â€” building a minimal RAG pipeline to handle Level 1 questions like â€œWho is the author?â€ or â€œWhat did Alice drink?â€

The goal will be simple:  
Can my system recall *exact truths* from a story â€” without hallucination, without confusion, and without magic?

---

## ðŸ§ª Try AliceEval Yourself

If youâ€™d like to follow along (or fork the journey), you can grab the starter code and evaluation datasets:

- Initial project scaffold: [Alice-in-RAG-land repository](https://github.com/lazycoder1/Alice-in-RAG-land/tree/base)
- Evaluation question sets: [`sample_data/eval`](https://github.com/lazycoder1/Alice-in-RAG-land/tree/base/sample_data/eval)

Feel free to remix the setup, run the evals, and share how your RAG system navigates Wonderland.

> â€œBegin at the beginning,â€ the King said gravely, â€œand go on till you come to the end: then stop.â€  
> â€” *Alice, Chapter 12*

Thatâ€™s exactly what I plan to do.  
One level at a time, one rabbit hole deeper â€” until this system can make sense of Wonderland.

---

*This marks the beginning of the AliceEval journey â€” a framework to understand not just RAG systems, but reasoning itself.*
